{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ea0d3-cc1c-41fc-a1c3-896219369a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################## GENERAL IDEA ###################################################################\n",
    "###################################################################################################################################################\n",
    "############################################################### 1. PRE PROCESSING #################################################################\n",
    "###################################################################################################################################################\n",
    "## Create a data frame from csv file, then create two data frames one for each Station types (start, end) for easier data handling. \n",
    "## Making sure data are sorted by datetimes, handling missing data (if any), getting rid of data we do not care about, converting certain columns \n",
    "## to certain data types if needed.\n",
    "## Then, create intervals and calculate values for each interval, handle upper/lower interval problems, and finally creating the final time_serie, \n",
    "## handling missing values if necessary. \n",
    "## All of the above are being conducted inside a function wich returns the final time series. \n",
    "## I did this because I wanted to easily create different time series using different intervals for testing purposes.\n",
    "## At the end of pre processing, we devide the time series into training and testing data. This is also being conducted in a function because\n",
    "## I wanted to easily create different training/testing data analogies for testing purposes.\n",
    "###################################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9b842-5da1-4e7f-a9cb-80049888c34b",
   "metadata": {},
   "source": [
    "**PREPROCESSING OF DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477e91d4-086c-416f-b81d-e931cd6391c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Time series creating function, using a file name and an integer representing the interval in hours ###########################\n",
    "\n",
    "# Importing pandas library\n",
    "import pandas as pd\n",
    "\n",
    "def csvDataToTimeSerie(fileName, timeInterInHours):  \n",
    "    # Creating a pandas data frame with the raw data of the csv file\n",
    "    raw_df = pd.read_csv(fileName)\n",
    "\n",
    "    # Creating separate data frames for start and end stations\n",
    "    \n",
    "    raw_start_df = raw_df[['TripId', 'StartTime', 'StartStationId']]\n",
    "    raw_end_df = raw_df[['TripId', 'EndTime', 'EndStationId']]\n",
    "    \n",
    "    # Making sure the data we are going to work on are sorted by timestamp\n",
    "    \n",
    "    raw_start_sorted_df = raw_start_df.sort_values(by='StartTime')\n",
    "    raw_end_sorted_df = raw_end_df.sort_values(by='EndTime')\n",
    "    \n",
    "    # Keeping only data that we want in each data frame (deleting entries where station id is not equal to 1)\n",
    "    # Also resetting the data frames' indexes for better visualization-manipulation of data\n",
    "    \n",
    "    condition = raw_start_sorted_df['StartStationId'] == 1\n",
    "    raw_start_sorted_df = raw_start_sorted_df[condition]\n",
    "    raw_start_sorted_df = raw_start_sorted_df.reset_index(drop='True')\n",
    "    \n",
    "    condition = raw_end_sorted_df['EndStationId'] == 1\n",
    "    raw_end_sorted_df = raw_end_sorted_df[condition]\n",
    "    raw_end_sorted_df = raw_end_sorted_df.reset_index(drop='True')\n",
    "    \n",
    "    # Checking if there are NaN values in the the raw data frames\n",
    "    \n",
    "    start_df_nan_check = raw_start_sorted_df.isna().any()\n",
    "    end_df_nan_check = raw_end_sorted_df.isna().any()\n",
    "    # In this project there are non. If there where, we would have to decide how to deal with the empty spots\n",
    "    \n",
    "    # Converting Time columns to timestamps so that certain functions can be used on them\n",
    "    \n",
    "    raw_start_sorted_df['StartTime'] = pd.to_datetime(raw_start_sorted_df['StartTime'])\n",
    "    raw_end_sorted_df['EndTime'] = pd.to_datetime(raw_end_sorted_df['EndTime'])\n",
    "\n",
    "    # Defining the start and end timestamps of the time series\n",
    "    # First we compare the min and max timestamps from the two data frames\n",
    "    # and we keep the overall min and max timestamps\n",
    "    \n",
    "    start_time_1 = raw_start_sorted_df['StartTime'].min()\n",
    "    start_time_2 = raw_end_sorted_df['EndTime'].min()\n",
    "    if (start_time_1 > start_time_2):\n",
    "        start_time = start_time_2\n",
    "    else:\n",
    "        start_time = start_time_1\n",
    "    \n",
    "    end_time_1 = raw_start_sorted_df['StartTime'].max()\n",
    "    end_time_2 = raw_end_sorted_df['EndTime'].max()\n",
    "    if (end_time_1 > end_time_2):\n",
    "        end_time = end_time_1\n",
    "    else:\n",
    "        end_time = end_time_2\n",
    "    \n",
    "    # Then we round the starting and ending hour (to the floor and ceiling hours respectively)\n",
    "    \n",
    "    start_time = start_time.floor('h')\n",
    "    end_time = end_time.ceil('h')\n",
    "    \n",
    "    # This if will take action only if the timeInterInHours exactly devides 24 (total hours per day)\n",
    "    # Not necessary but if the above is the case, then intervals deviding the total period will not split between different days\n",
    "    \n",
    "    if 24 % timeInterInHours == 0:\n",
    "        start_mod = start_time.hour % timeInterInHours\n",
    "        if start_mod != 0:\n",
    "            start_time -= pd.Timedelta(hours=start_mod)\n",
    "        \n",
    "        end_mod = end_time.hour % timeInterInHours\n",
    "        if end_mod != 0:\n",
    "            end_time += pd.Timedelta(hours=end_mod)\n",
    "    \n",
    "    # Creating the final timestamp values of the time series using a frequency of timeInterInHours hours\n",
    "    # and inserting it into a pandas data frame\n",
    "    # Each timestamp of the time_serie will indicate the demand for the time period [current_timestamp, current_timestamp+Xhours)\n",
    "    \n",
    "    interval = str(timeInterInHours) + 'h'\n",
    "    timestamps = pd.date_range(start=start_time, end=end_time, freq=interval)\n",
    "    \n",
    "    # There is a change that the max timestamp created is less than the end_time of our data.\n",
    "    # If this is the case we add one more interval, so that we will not miss any data when creating the time serie\n",
    "    \n",
    "    if (timestamps[-1] < end_time):\n",
    "        extra_timestamp = timestamps[-1] + pd.Timedelta(hours=timeInterInHours)\n",
    "        timestamps = timestamps.append(pd.DatetimeIndex([extra_timestamp]))\n",
    "    \n",
    "    # Creating the total period for the time serie\n",
    "    \n",
    "    pre_time_serie = pd.DataFrame({'Time': timestamps})\n",
    "    \n",
    "    # Calculating the bicycles taken and returned in each period,\n",
    "    # and then calculating the demand in ech period by subtracting the above\n",
    "    \n",
    "    pre_time_serie['Taken'] = 0\n",
    "    pre_time_serie['Returned'] = 0\n",
    "    \n",
    "    # Inserting the taken bicycle values\n",
    "    i = 0\n",
    "    max_i = raw_start_sorted_df.index.max()\n",
    "    max_index = pre_time_serie.index.max()\n",
    "    for index in range(0, max_index):\n",
    "        count = 0\n",
    "        cur_time = raw_start_sorted_df.loc[i, 'StartTime']\n",
    "        low_time = pre_time_serie.loc[index, 'Time']\n",
    "        high_time = pre_time_serie.loc[index+1, 'Time']\n",
    "        while (cur_time>=low_time and cur_time<high_time):\n",
    "            count += 1\n",
    "            i += 1\n",
    "            if (i>max_i): break\n",
    "            cur_time = raw_start_sorted_df.loc[i, 'StartTime']\n",
    "        pre_time_serie.loc[index, 'Taken'] = count\n",
    "        if (i>max_i): break\n",
    "    \n",
    "    # Inserting the returned bicycle values\n",
    "    i = 0\n",
    "    max_i = raw_end_sorted_df.index.max()\n",
    "    for index in range(0, max_index):\n",
    "        count = 0\n",
    "        cur_time = raw_end_sorted_df.loc[i, 'EndTime']\n",
    "        low_time = pre_time_serie.loc[index, 'Time']\n",
    "        high_time = pre_time_serie.loc[index+1, 'Time']\n",
    "        while (cur_time>=low_time and cur_time<high_time):\n",
    "            count += 1\n",
    "            i += 1\n",
    "            if (i>max_i): break\n",
    "            cur_time = raw_end_sorted_df.loc[i, 'EndTime']\n",
    "        pre_time_serie.loc[index, 'Returned'] = count\n",
    "        if (i>max_i): break\n",
    "    \n",
    "    # Creating the resulting time serie by deleted columns that are not needed,\n",
    "    # deleting the last row, which does not represent a period we want\n",
    "    # and make the timestamps' column the index\n",
    "    # We do not have to handle missing values etc,\n",
    "    # because as we can see from the raw data set, data is spread in any kind day/hour\n",
    "    \n",
    "    # If we had to deal with missing values, then usually one of three methods is chosen:\n",
    "    # 1. Fill with front interval's value with time_serie.Demand.fillna(method = 'bfill') a.k.a \"back filling\"\n",
    "    # 2. Fill with back interval's value with time_serie.Demand.fillna(method = 'ffill') a.k.a \"front filling\"\n",
    "    # 3. Fill with the mean of all time_serie data with time_serie.Demand.fillna(value = time_serie.Demand.mean()) -- NOT good choice for time series\n",
    "    #    because usually we observe a periodicity in data and data are strongly connected with neighbor data\n",
    "    \n",
    "    pre_time_serie['Demand'] = pre_time_serie['Returned'] - pre_time_serie['Taken']\n",
    "    time_serie = pre_time_serie.copy()\n",
    "    time_serie.drop(columns=['Returned'], inplace=True)\n",
    "    time_serie.drop(columns=['Taken'], inplace=True)\n",
    "    time_serie.drop(time_serie.index[-1], inplace=True)\n",
    "    time_serie.set_index('Time', inplace=True)\n",
    "    return time_serie\n",
    "\n",
    "############################################ Function to split the time series into training and testing data #######################################\n",
    "\n",
    "def timeSerieSplit(time_serie, training_perc, testing_perc):\n",
    "    size = int(len(time_serie)*training_perc)\n",
    "    training_data = time_serie.iloc[:size]\n",
    "    testing_data = time_serie.iloc[size:]\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30d5079-3ec0-430e-8b17-96e453a9dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Demand\n",
      "Time                       \n",
      "2023-02-01 00:00:00      -1\n",
      "2023-02-01 02:00:00       0\n",
      "2023-02-01 04:00:00       1\n",
      "2023-02-01 06:00:00     -10\n",
      "2023-02-01 08:00:00      -7\n",
      "...                     ...\n",
      "2023-02-28 14:00:00       4\n",
      "2023-02-28 16:00:00       8\n",
      "2023-02-28 18:00:00       6\n",
      "2023-02-28 20:00:00       4\n",
      "2023-02-28 22:00:00      10\n",
      "\n",
      "[336 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "########### Creating a time series from the data.csv file's data, with a 2 hour interval and splitting into 70% training, 30 % testing data ############\n",
    "\n",
    "time_serie = csvDataToTimeSerie('data.csv', 2)\n",
    "print(time_serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323a2e5-35c2-4049-a689-7fe35f58011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the time serie through the data frame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (30, 8)\n",
    "plt.plot(time_serie['Time'], time_serie['Demand'])\n",
    "plt.title('Bicycle Demand')\n",
    "plt.xlabel('Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Demand')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdaa9a3-3eaa-45f3-8339-121bb30c8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sc\n",
    "import pylab\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 8)\n",
    "sc.probplot(time_serie.Demand, plot = pylab)\n",
    "pylab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
